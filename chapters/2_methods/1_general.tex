\section{Materials \& Methods}
\subsection{Experimental Procedure and Setup \textcolor{green}{Sezen, Lukas}}
Participants were informed of the nature of the experiment, recording and anonymization procedures and signed a consent form approved by the local ehtics committee of the Department of Psychology and Ergonomics at the TU Berlin. 20 participants (X female, mean age = X (Y sd)) were recruited through an online tool provided by the Department of Psychology and Ergonomics and through local listings. Participants were right-handed, had normal or corrected to normal vision and had no prior experience with vibrotactile feedback in virtual reality. Participants were compensated with 10 Euros per hour. Data of the first subject had to be removed from further analyses due to data recording error.

Using an HTC Vive VR Headset with the Vive Deluxe Audio Strap and a Vive Tracker (company details) attached to the right hand, a 3D object selection task was presented on a virtual table placed on an infinite white plane build using Unity VR (Version, company details). White cubes appeared at random in either the center, to the left or to the right of the participant, equidistant from a starting position. The time of a new cube spawning was randomized between 1-2 seconds after starting a trial. Participants were tasked to select the cube with their index finger and, upon completion, move their hand back to a resting position indicated on the table. The task was completed in two blocks of 300 trials each, with one block providing visual-only feedback, i.e. the cube changing its color from white to red upon selecting, and one block visual-tactile feedback, i.e. the cube changed color plus a small vibrotactile pulse indicated selection contact. Placed under the index fingertip, a vibration motor (Model \textit{308-100} from \textit{Precision Microdrives}), generating 0.8g at 200Hz and measuring 8mm in diameter was driven at 70mA by a 2N7000 MOSFET connected to an Arduino output pin at 3V. An initial 24 trial training session was followed by the two experimental blocks (interchanged across participants), each followed by two questionnaires, NASA-TLX and IPQ. For the main experimental manipulation of asynchrony, 25\% of the trials (equaling 75 asynchronous trials per feedback block) exhibited spatio-temporal asynchrony in line with established oddball paradigms. Object selection was triggered prematurely by bounding a spherical collider to the cube and enlarging it by 350\% in comparison to a collider bounded to the shape of the cube in the synchronous trials. Asynchronous trials were sorted in an pseudo-randomized sequence following synchronous trials, i.e. between one and five synchronous trials preceeded an asynchronous trial. Extended task and apparatus descriptions can be found elsewhere \cite{Gehrke_2019}.
% todo add movie, figure and references

\subsection{Motion Capture and EEG Recording \textcolor{green}{Sezen, Lukas Marius, Klaus}}
EEG was recorded using 64 active Ag/AgCl electrodes placed according to the extended international 10â€“20 system \cite{chatrian_ten_1985}. The electrode at position FP2 was detached from the cap and placed under the left eye (EOG). Impedances were kept under 30 \si{\kohm}. EEG was sampled at 500 Hz and amplified using BrainAmp DC amplifiers (Brainproducts GmbH, Gilching, Germany). Hand (and head) movements were sampled at 90 Hz when coming out of the HTC Vive processing cascade. Samples were recorded and synchronized using labstreaminglayer \cite{}. Motion capture data was filtered with a 6Hz lowpass filter and upsampled to match EEG frequency using MoBILAB routinges \cite{} for concurrent analyses.

\subsection{EEG Preprocessing and Independent Component Analysis (ICA)}
EEG data preprocessing and ICA were performed with Matlab 2019b (MATLAB, The MathWorks Inc., Natick, MA, USA), using the EEGLAB toolbox \cite{delorme_eeglab:_2004} and our 'BeMoBIL Pipeline' \cite{klug2018bemobil} scripts and functions. The single subject data was lowpass filtered with 124Hz and down-sampled to 250Hz. Channels which were contaminated with artifacts were automatically rejected using the PREP pipeline \cite{bigdely-shamlo_prep_2015} 'FindNoisyChannel' function, which is selecting bad channels by amplitude, the signal to noise ratio and correlation with other channels. Rejected channels were then interpolated while ignoring the EOG channel, and finally re-referenced to average reference (data A). The data was then filtered with a 1 Hz highpassfilter (data B), a first adaptive mixture independent component analysis, AMICA \cite{palmer_newton_2008}, was used to identify eye related independent components (ICs) which were projected out of the sensor data (data A). For this, the rank was reduced by one for average reference use and further, the number of interpolated channels in the respective data set. To identify eye components IClabel  \cite{pion2019iclabel} was used, whereas components exceeding a value of 0.7 for the 'eye' class were defined as eye components. Then, to detect segments of noisy data, an automated time domain cleaning (see \citet{gramann2018heading}) on the time domain was performed on narrowly filtered data from 1 to 40 Hz. The data was therefore first split into 1 second long segments for which the mean absolute amplitude and standard deviation of all channels as well as the Mahalanobis distance of all channel mean amplitudes were calculated. All three methods results were then joined together in order to rank all segments. The 12\% highest ranking noisy segments were selected for rejection and an additional buffer of +/- 0.49 sec was added around each segment resulting in about 15\% rejected data for each subject. This data was rejected from data B and a second AMICA was calculated on this time domain cleaned data. A dipole fitting \cite{oostenveld2002validating} procedure was performed for each spatial filter using the 10-20 standard electrode locations and a boundary element head model (BEM) based on the MNI brain (Montreal Neurological Institute, MNI, Montreal, QC, Canada) and the spatial filter information was then copied back to the preprocessed, interpolated and average referenced data set (data A). Ultimatelty, all ICs with a smaller than .5 'brain' label by ICLabel were projected out of the data resulting in the final dataset of likely brain sources and their projections to the channels.

\subsection{Event-related Feature Extraction}
Data was epoched -3 to +2 seconds around the 600 \textit{cube selection} events and trials were removed (a) if the reaction time between cube \textit{spawn} and \textit{selection} exceeded two seconds or (b) large potential fluctuations in the channels were detected via EEGLABs \textit{pop_autorej}.
% todo how many trials were removed 
For each remaining single trial we build event-related potentials for channels and independent components (ERP), event-related velocities, i.e. the magnitude of velocities in x, y and z direction (ERV) as well as event-related time-frequency decompositions (ERSP). Time-frequency decomposition were computed via newtimef \textit{newtimef} with 3 to 80 Hz in logarithmic scale, using a wavelet transformation with 3 cycles for the lowest frequency and a linear increase with frequency of 0.5 cycles. Single-trial baseline vectors contained average power per frequency bin in the -200 to 0 ms window preceding cube \textit{spawns}. Where applicable, grand average ERPSs are computed by first averaging both trial data and baselines across trials in power then dividing trial data by baseline and transforming the outcome to logarithmic scaling. ERPs are plotted after bandpass filtering with a low and high cutoff at 0.1 and 15 Hz respectively.

\subsection{Classifier, Classifier Scalp Projections and Localization of Components relevant to Classification}
Following \citet{Zander2016} a regularized linear discriminant analysis classifier was trained per participant with all asynchronous trials constituting class 1 and a random sample of an equal size of synchronous trials labeled class 2. Using Matlab 2014a (MATLAB, The MathWorks Inc., Natick, MA, USA) with the open-source toolbox BCILAB ver. 1.4 the classifier was trained on windowed means as features. Therefore, average amplitudes of all channels and eight sequential 50 ms time windows between 50 and 450 ms following \textit{cube selection} were extracted following resampling to 100 Hz and band-pass filtering from 0.1 to 15 Hz. For robust performance estimation, a 5 x 5 nested cross-validation was used to calculate the classifiers reliability.

In order to learn what regions of the brain the classifier specifically relied on, we first transformed participants LDA filters at each time window to LDA patterns reflecting a mixture of scalp activations with regards to the discriminative source activity \cite{Haufe2014a, Zander2016, Krol2019}. Subsequently, the relevance for classification can be computed using LDA filter weights per time window and the ICA umixing matrix. The equivalent current dipole models of independent compontents were then weighted by their relevance and ultimately visualized via dipoleDensity plots \cite{}. We established the highest relevance voxel via visual inspection and used it as a seed (ROI) for group-level IC clustering.
% todo add miyakoshi dipoledensity
% todo add movie

\subsection{Clustering Independent Components for Group-Level Analyses}
To allow for group-level analyses across independent components, we clustered components based on their equivalent dipole locations (weight=6), grand-average ERSPs (weight=3), mean log spectra (weight=1), and scalp topography (weight=1), using a region of interest (ROI) driven repetitive k-means clustering approach \cite{cleaning_FH2018}. The weighted IC measures were summed and compressed using PCA, resulting in a 10-dimensional feature vector for clustering. ICs were clustered by applying the k-means algorithm with k equaling the median number of ICs retained across subjects. ICs with a distance of more than three standard deviations from any final centroid mean were considered outliers. To ensure replicability of the clustering, we employed the same clustering approach reported in \cite{cleaning_FH2018}. After applying desirable weights (number of participants: 2, ICs/participants: -2, spread: -1, RV: -1, distance from ROI: -2, Mahalanobis distance from the median: -1) the final clustering solution contained the ICs from X participants, a ratio of X ICs per participant, a spread of X, a mean RV of X\%, and a distance of X units in the MNI space for the cluster of primary interest.
% todo add clustering results

\subsection{Single-Trial Regression and Multiple Comparison Correction using Threshold-Free Cluster Enhancement}
% - mass univariate regression at the single subject level (Kutas rERP, Groppe, Pernet, Cavanagh, Cohen). Averaging betas and pvals, then do tfce transform on the mean and infer on the tfce statistic? \todo{check if this method correct, how did cohen do it?}
% - paired ttest with bootstrap-tfce multiple comparison correction \citep{SMITH200983} to make inferences about the interaction
% - Grand Average Statistics