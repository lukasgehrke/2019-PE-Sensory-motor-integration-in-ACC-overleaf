% aim for 1500 words: 1473 -> nice, don't add, improve!
\section{Discussion}

%%% Statement/Summary of principal findings
With this study, we contributed a new approach to automatically detect conflicts in visuo-tactile sensory integration in VR based on a \textcolor{red}{\st{BCI}} classifier using ERPs. Our work was motivated by the need to describe implicit neural signatures enabling accurate and reliable classification. We achieved a $\sim$77 \% classification accuracy detecting visuo-tactile glitches in a reach-to-tap task in VR. The midline cingulate cortex as well as a distributed network of parieto-occipital EEG sources enabled the classification success.

We discuss two noteworthy points: (1) the missing contribution of post-error movement adaptation to the classification and (2) challenges for \textcolor{new}{ERP-based} BCI relying on embodied predictive coding in natural interaction.

%%% filling the gap detail #1
\subsection{Using Post-error Adaptation to Detect Visuo-Tactile Mismatches during Interaction with Virtual Worlds}

We explored whether a movement metric, post-error adaptation, can supplement the classification and motivate a multimodal approach. We hypothesized a trial-to-trial adaptation in movement behavior as an implicit behavioral reflection of the effectiveness of our `VR glitch' experimental manipulation.~\cite{Dutilh2012-ps} have shown that correlations of brain signals with global averages of post-error slowing metrics may be moderated by confounding \textit{cognitive} processes, e.g. fluctuating concentration levels. Therefore, we looked at the rate of change in `tap time'. Between two subsequent match trials there was no change in `tap time'. However, `tap time' increased in the trial following a mismatch trial. This post-error adaptation confirmed our manipulation, since the visuo-tactile VR glitch impacted subsequent behavior. Further, this finding rules out the possibility of an automatic behavior in which participants were unaware of the manipulation. Since the task featured 600 trials, this was not unlikely. 

Our findings support the literature on post-error adaptation, with participants taking a slightly more cautious approach following VR glitches~\cite{Rabbitt1977-yg}. This speed decline has frequently been observed to facilitate increasing accuracy on subsequent trials~\cite{Ridderinkhof2004-rz}. Here, cognitive control processes inhibit motor execution, presumably by closely monitoring, and raising, cortical activity thresholds~\cite{Botvinick2001-bs}.

In summary, we believe our data captures `prediction errors', violations of goal-directed behavior under consideration of the predicted action outcome. Further, we believe cognitive control mechanisms to monitor and adjust subsequent motor output with one objective being an increase in behavioral accuracy. However, due to the small effect size, our `tap time' metric did not enable a successful classification as compared to the EEG features. The low behavioral classification rate might be a consequence of the missing framing of our task, not priming participants on a speed-accuracy trade-off. Not collecting an accuracy metric is a shortcoming that should be improved in subsequent works, for example as in~\cite{Purcell2016-li}. However, we note that increasing the amount of data subjected to the behavioral classification approach increased the accuracy of the classifier substantially (see supplementary material). In order to obtain robust cross-validated classification accuracy estimates, we chose to subject balanced classes to the cross-validation scheme and hence maintain a 50\% theoretical chance level.

%%% filling the gap detail #2
\subsection{\textcolor{n}{Towards} BCI based on Embodied Predictive Coding during Interaction with Virtual Worlds}

In order to describe a robust ERP feature representing prediction errors, we localized their EEG source origin and found two loci: (1) the midline cingulate cortex and (2) a distributed network in parieto-occipital areas. 

The role of midfrontal EEG source activity has frequently been linked to cognitive control processes~\cite{Ridderinkhof2004-rz, Cavanagh2014-mm, Cooper2019-im}. Crucially, these studies employed a stationary setup, limiting participants' interaction with the task environment. However, environmental affordances surpass the visual domain. Particularly in humans, a proclivity to use both hands to act on the environment has emerged and is greatly trusted upon, for example when finding your way in the dark~\cite{Gehrke2018-jm, Gehrke2021-ml, Miyakoshi2021-ni}. In fact, many tasks can be completed without concurrently consulting the visual domain, such as typewriting or even reaching for a cup; these typically rely heavily on the tactile and proprioceptive sense and as such are denoted as eyes-free interactions.

In our voluntary, albeit instructed, tapping task, we observed a frontal prediction error negativity, `PEN', (at electrode FCz) to exhibit a familiar time course as compared to stationary setups reporting MMN, see difference wave in figure \ref{erp}. In line with the MMN literature, we observed a stronger early negative deflection in mismatch trials as compared to the match trials, see figure \ref{erp}.~\cite{Zander2016-ed} report a single `PEN' source origin in anterior cingulate cortex, however in our study, besides midline cingulate sources, sources in parieto-occiptal areas contributed to the successful classification. Previously,~\cite{Savoie2018-ad} observed an effect of prediction errors about the visual consequences of the current motor action in a reaching task in parietal electrodes contralateral to the reaching hand. The authors conclude a role of the dorsal processing stream, processing the `where' in visuomotor `PEs'. Considering the classifier weighting in our task in the time periods between 150 to 200 ms as well as 200 - 250 ms, we take note of a parieto-occipital reliance for match/mismatch separation in the earlier time window which was followed by a more pronounced weighting on frontal midline sources in a following time window.

Hence, we observed our classifier to first rely on parieto-occipital sources and subsequently on frontal midline sources in the typical time range of the MMN. This may indicate the role of embodied affordances in our immersive reaching task. Attention modulating cognitive control during `PEs' may be represented in the MMN. In stationary setups or `motor-passive' paradigms, such as in~\cite{Zander2016-ed}, no countermeasure to correct the `PE' exists. This may explain a heavy role of midline cingulate activity in classification with no other sources contributing. However, even for a simple task like reaching for an object, several sensory signals (e.g., visual, tactile and proprioceptive feedback) are continuously gathered and analyzed to efficiently interact with/in a dynamically changing environment. To compensate for the sensory noise within the nervous system and for the uncertainties in the dynamic environment different movement-related sensory cues have to be integrated. To gain an overall representation of the body position, movement and acceleration, the most reliable sensory information must be enhanced while the most noisy ones must be diminished~\cite{Fetsch2011-bp}, i.e. multisensory integration. With increasing immersion, processing gets more accurate and therefore might trigger a hierarchical cascade of `PE' processing~\cite{Singh2021-qc}. Here, multisensory integration in parieto-occipital regions precedes action outcome evaluation and cognitive control supported by midline cingulate cortex structures. However, the fact that our classifier relied on parieto-occipital source activity is direct evidence for `PE' processing. One possible explanation is that sensory `PEs' may already be resolved at early stages in the processing cascade instead of an inefficient signal forwarding to frontal brain areas.

%%% Limitations in filling the gap
\subsection{Limitations}

Our classification results rely on the presence of a binary class label, `match' - `mismatch'. For online application where no such labels exist, this poses a problem. However, the presented paradigm may serve as a \textit{calibration}, with subsequent online application using a moving window providing a class probabilities. When a threshold is exceeded, the system trained on labeled glitches provides information on the current user experience of visuo-tactile congruency. It is interesting to follow up our investigation with regards to the level of haptic immersion. In~\cite{Gehrke2019-og} we have shown a dependence of the level of haptic immersion on the `PE' early negative component. This hints at a potentially better classification accuracy with increasing immersion and is an objective for future research.

To allow for a full reproduction of our results, we provide the BIDS formatted data as well as all processing code alongside this publication. We chose automated over manual processing. However, problems remain in automated labeling of EEG sources. As evident in figure~\ref{lda_loc} sources localized to the eyes did contribute to the classification. More stringent vetting of EEG sources could make the results to rely exclusively on brain sources. However, using the eye activity features for classification is useful as long as it is reliable. This is especially relevant when using low-density EEG systems, such as consumer market products and it would be interesting to dissociate the different sources' contribution to the classification.

Lastly, one way to validate `PEN' as a correlate of sense of presence would be a correlation with established presence questionnaires~\cite{Witmer1998-ew,Schubert2003-sq}. We believe that due to the highly repetitive experimental design and very subtle experimental manipulation, frequently asking questions would not yield valid results in the sense that frequently breaking the ongoing presence experience would bias the very construct we aimed at measuring. Recently~\cite{Grassini2021-tc} reported a correlation of late ERP components in central electrodes with the subjective presence experience. The authors used an auditory irrelevant probe paradigm and showed that ERP fluctuations to auditory distractor probes coincided with presence ratings. This approach relies on probing the user's overall attentional state. Instead, our proposed approach directly probes the user's internal model of their environment providing a precise task-relevant marker for neuroadaptive interfaces \cite{Krol2020-lj}.


%%% 'Contributions beyond'
\subsection{Conclusions \& Outlook: Towards a Robust Metric of Presence Experience in Virtual Worlds}

Midline cingulate EEG sources contributed to prediction error ERPs, `PENs', and may serve as a robust source to detect violations of user's predictions about the interaction with virtual worlds~\cite{Gehrke2019-og, Si-mohammed2020-ru, Zander2016-ed}. This source origin can be specifically and repeatedly probed for real-time BCI purposes, informing the technical system about the user's mental representation generating the predictions~\cite{Krol2020-lj, Zander2016-ed}. If follow up studies replicate and extend on our classification success several benefits emerge: (1) the ERP-based measure to continuously evaluate haptic immersion gains significant robustness and reliability. (2) This will in turn motivate further research on the PE paradigm moving towards implicit measures of the user's subjective experience. (3) We believe this paves the way for fast and reliable real-time adaptation as the EEG feature search space is significantly reduced. However, our results also show a network of distributed parieto-occipital EEG sources contributing to the classification success. This indicates the challenges remaining in scenarios with a higher level of physical immersion. 

With this work, we hope to contribute to the design of reliable neural interface technology for interaction with virtual worlds.




%%% writing resources
% However, the predictive brain still receives noticeably less realistic sensory cues from the interaction with/in VEs when compared to the sensory richness of the physical interaction. Therefore, the multisensory integration processes needs to fill in more of the missing (or contradicting) sensory information by interpolating and augmenting the computer-simulated sensory information~\cite{Fetsch2011-bp}. Overall, integrating additional sensory modalities to the VE leads to an enhanced intersensory experience, so that the mental representation of the virtual world is more reliable and the level of presence is enhanced~\cite{Dinh1999-qe, Bohil2011-gu}.